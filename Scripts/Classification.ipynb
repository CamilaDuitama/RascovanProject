{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc07d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from dask.distributed import Client, progress\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "#client.shutdown()\n",
    "#client.close()\n",
    "dask.config.set({'temporary_directory': '/pasteur/sonic/scratch/public/cduitama/RascovanProject/tmp/'})\n",
    "#dask.config.set({\"optimization.fuse.ave-width\": 5})\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6577a3",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39f391d",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatrices=dict()\n",
    "ikmers=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRR_aSGenomes_HS_Oral=pd.read_csv(\"Metadata/aSGenomes/aSGenomes_HS_Oral_SRR.txt\",header=None,names=[\"SRR_accession\"])\n",
    "SRR_mMetagenomes_HS_Oral=pd.read_csv(\"Metadata/mMetagenomes/Oral_HS_mMetagenomes_SRR.txt\",\\\n",
    "                                     header=None,names=[\"SRR_accession\"])\n",
    "\n",
    "HS_Oral_metadata=pd.read_csv(\"Metadata/aMetagenomes/HS_Oral_metadata.csv\")\n",
    "SRR_HS_Oral=[\"Kmer\"]+list(HS_Oral_metadata[\"SRR_accession\"])\n",
    "\n",
    "SRR_HS_Oral_aMetagenomes=SRR_HS_Oral[1:]\n",
    "SRR_HS_Oral_aSGenomes=list(SRR_aSGenomes_HS_Oral.SRR_accession)\n",
    "SRR_HS_Oral_mMetagenomes=list(SRR_mMetagenomes_HS_Oral.SRR_accession)\n",
    "names=SRR_HS_Oral_aMetagenomes+SRR_HS_Oral_aSGenomes+SRR_HS_Oral_mMetagenomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c14073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_take=np.genfromtxt(\"Classification/list_of_indeces_of_RepresentativeSample.csv\",delimiter=\",\")\n",
    "\n",
    "print(len(to_take))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039eb4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_total=dd.read_table(\"kmMatrices/combination/combination_whole_matrix.txt\",sep=\" \",header=None,names=names)\n",
    "all_kmers=combined_total.Kmer.compute()\n",
    "all_kmers=all_kmers.reset_index()\n",
    "all_kmers=all_kmers.drop(\"index\",axis=1)\n",
    "ikmers[\"RepresentativeSample\"]=all_kmers.iloc[to_take]\n",
    "icombined_total=combined_total[combined_total[\"Kmer\"].isin(ikmers[\"RepresentativeSample\"][\"Kmer\"])]\n",
    "imatrices[\"RepresentativeSample\"]=icombined_total.drop(\"Kmer\",axis=1).values\n",
    "\n",
    "imatrices[\"RepresentativeSample\"]=imatrices[\"RepresentativeSample\"].persist()\n",
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "ecombined_total=imatrices[\"RepresentativeSample\"]\n",
    "b_ecombined_total = Binarizer().fit_transform(ecombined_total)  # fit does nothing.\n",
    "\n",
    "import dask.array as da\n",
    "from sklearn.decomposition import PCA\n",
    "#Here I convert the np array into a Dask array using chunks of 1 GB\n",
    "dX_15 = b_ecombined_total.transpose()\n",
    "pca_15 = PCA(n_components=2)\n",
    "to_plot_15=pca_15.fit(dX_15)\n",
    "\n",
    "np.savetxt(\"Preprocessed_data/combination/RepresentativeSample_Binarization_PCA.txt\", to_plot_15.components_, delimiter=',')\n",
    "\n",
    "print(to_plot_15.explained_variance_ratio_)\n",
    "\n",
    "print(to_plot_15.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d78224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt(\"Classification/RepresentativeSample_binarized.csv\", b_ecombined_total, delimiter=',')\n",
    "\n",
    "attempt=dd.read_table(\"Classification/RepresentativeSample_binarized.csv\",delimiter=\",\").values\n",
    "\n",
    "b_ecombined_total.shape\n",
    "\n",
    "attempt=attempt.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e024a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1=Ancient\n",
    "#2=NonAncient\n",
    "to_take=one+two+three+four+five+six+seven\n",
    "labels=[]\n",
    "labels=labels+[False]*len(one)\n",
    "labels=labels+[False]*len(two)\n",
    "labels=labels+[True]*len(three)\n",
    "labels=labels+[False]*len(four)\n",
    "labels=labels+[True]*len(five)\n",
    "labels=labels+[False]*len(six)\n",
    "labels=labels+[True]*len(seven)\n",
    "Data = pd.DataFrame(list(zip(to_take, labels)),\n",
    "               columns =['Index', 'Label'])\n",
    "Data.sort_values(by='Index' , inplace=True)\n",
    "Data=Data.reset_index()\n",
    "\n",
    "Data=Data.drop(\"index\",axis=1)\n",
    "Data.head()\n",
    "\n",
    "np.savetxt(\"Classification/Labels_RepresentativeSample.csv\",Data[\"Label\"], delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f631cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_RepresentativeSample=np.genfromtxt(\"Classification/Labels_RepresentativeSample.csv\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df29357f",
   "metadata": {},
   "source": [
    "## Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(n_jobs=-1)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    LR.fit(X_train, y_train)\n",
    "    y_test_predicted_LR=LR.predict(X_test)\n",
    "    y_train_predicted_LR=LR.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecbaf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "\n",
    "y_train.shape\n",
    "\n",
    "X_test.shape\n",
    "\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b18e1a",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train, y_train_predicted_LR)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_test_predicted_LR)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_train,y_train_predicted_LR)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,y_test_predicted_LR)\n",
    "\n",
    "len(np.where(labels_RepresentativeSample==False)[0])\n",
    "\n",
    "len(np.where(labels_RepresentativeSample==True)[0])\n",
    "\n",
    "len(np.where(y_train!=y_train_predicted_LR)[0])\n",
    "\n",
    "len(np.where(y_train==y_train_predicted_LR)[0])\n",
    "\n",
    "y_train_score_LR=LR.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4fad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_train_score_LR)\n",
    "\n",
    "fig = px.area(\n",
    "    x=fpr, y=tpr,\n",
    "    title=f'ROC Curve for training set (AUC={auc(fpr, tpr):.4f})',\n",
    "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
    "    width=700, height=500\n",
    ")\n",
    "fig.add_shape(\n",
    "    type='line', line=dict(dash='dash'),\n",
    "    x0=0, x1=1, y0=0, y1=1\n",
    ")\n",
    "\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.update_xaxes(constrain='domain')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c6e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train, y_train_score_LR)\n",
    "\n",
    "# Evaluating model performance at various thresholds\n",
    "df = pd.DataFrame({\n",
    "    'False Positive Rate': fpr,\n",
    "    'True Positive Rate': tpr\n",
    "}, index=thresholds)\n",
    "df.index.name = \"Thresholds\"\n",
    "df.columns.name = \"Rate\"\n",
    "\n",
    "fig_thresh = px.line(\n",
    "    df, title='TPR and FPR at every threshold for training set',\n",
    "    width=700, height=500\n",
    ")\n",
    "\n",
    "fig_thresh.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig_thresh.update_xaxes(range=[0, 1], constrain='domain')\n",
    "fig_thresh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e11e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train,y_train_predicted_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca4fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_score_LR=LR.predict_proba(X_test)[:,1]\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_score_LR)\n",
    "\n",
    "fig = px.area(\n",
    "    x=fpr, y=tpr,\n",
    "    title=f'ROC Curve for test set (AUC={auc(fpr, tpr):.4f})',\n",
    "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
    "    width=700, height=500\n",
    ")\n",
    "fig.add_shape(\n",
    "    type='line', line=dict(dash='dash'),\n",
    "    x0=0, x1=1, y0=0, y1=1\n",
    ")\n",
    "\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.update_xaxes(constrain='domain')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_score_LR)\n",
    "\n",
    "# Evaluating model performance at various thresholds\n",
    "df = pd.DataFrame({\n",
    "    'False Positive Rate': fpr,\n",
    "    'True Positive Rate': tpr\n",
    "}, index=thresholds)\n",
    "df.index.name = \"Thresholds\"\n",
    "df.columns.name = \"Rate\"\n",
    "\n",
    "fig_thresh = px.line(\n",
    "    df, title='TPR and FPR at every threshold for test set',\n",
    "    width=700, height=500\n",
    ")\n",
    "\n",
    "fig_thresh.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig_thresh.update_xaxes(range=[0, 1], constrain='domain')\n",
    "fig_thresh.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abca10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_test_predicted_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_train,y_train_predicted_LR,target_names=[\"Non-ancient\",\"Ancient\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_test_predicted_LR,target_names=[\"Non-ancient\",\"Ancient\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eee0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Classification/LR/y_test_predicted_labels.csv\",y_test_predicted_LR,delimiter=\",\")\n",
    "np.savetxt(\"Classification/LR/y_train_predicted_labels.csv\",y_train_predicted_LR,delimiter=\",\")\n",
    "np.savetxt(\"Classification/LR/y_test_true_labels.csv\",y_test,delimiter=\",\")\n",
    "np.savetxt(\"Classification/LR/y_train_true_labels.csv\",y_train,delimiter=\",\")\n",
    "np.savetxt(\"Classification/LR/y_train_score_LR.csv\",y_train_score_LR,delimiter=\",\")\n",
    "np.savetxt(\"Classification/LR/y_test_score_LR.csv\",y_test_score_LR,delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
